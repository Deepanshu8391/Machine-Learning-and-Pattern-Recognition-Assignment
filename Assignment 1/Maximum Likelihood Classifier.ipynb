{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from numpy.linalg import inv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Deterministic Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g5(InputVector,CovarianceMatrix,MeanVector,ProbabilityOfClass5):\n",
    "    a=np.log(np.linalg.det(CovarianceMatrix))\n",
    "    a=float(a)/2\n",
    "    b=np.matmul(np.subtract(InputVector ,MeanVector),np.linalg.inv(CovarianceMatrix))\n",
    "    b=np.matmul(b,(np.subtract(InputVector ,MeanVector)).transpose())\n",
    "    b=float(b)/2\n",
    "    c=np.log(ProbabilityOfClass5)\n",
    "    return c-b-a\n",
    "\n",
    "\n",
    "def g6(InputVector,CovarianceMatrix,MeanVector,ProbabilityOfClass5):\n",
    "    a=np.log(np.linalg.det(CovarianceMatrix))\n",
    "    a=float(a)/2\n",
    "    b=np.matmul(np.subtract(InputVector ,MeanVector),np.linalg.inv(CovarianceMatrix))\n",
    "    b=np.matmul(b,(np.subtract(InputVector ,MeanVector)).transpose())\n",
    "    b=float(b)/2\n",
    "    c=np.log(ProbabilityOfClass5)\n",
    "    return c-b-a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# .csv files must be in same folder as this code if not then give the exact path name.\n",
    "\n",
    "df1 = pd.read_csv(\"P1_labels_train.csv\",header=None)    #Reading labels of training set\n",
    "df2 = pd.read_csv(\"P1_data_train.csv\",header=None)      #Reading data of training set\n",
    "df3 = pd.read_csv(\"P1_labels_test.csv\",header=None)     #Reading labels of test set\n",
    "df4 = pd.read_csv(\"P1_data_test.csv\",header=None)       #Reading data of test set\n",
    "\n",
    "label_train=df1.iloc[:,0]\n",
    "label_test=df3.iloc[:,0]\n",
    "label_train=np.asarray(label_train)                     #Labels of training set\n",
    "label_test=np.asarray(label_test)                       #Labels of test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for calculating missclassifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missclass(label_test,MeanClass5,CovarianceClass5,MeanClass6,CovarianceClass6,ProbailityOf5):\n",
    "    correct5=0 #correctly classified to class 5\n",
    "    correct6=0 #correctly classified to class 6\n",
    "    wrong5=0   #misclassified to class 5\n",
    "    wrong6=0   #misclassified to class 6\n",
    "    label=0\n",
    "    for i in range(0,len(label_test)):\n",
    "        if g5(np.asarray(df4.iloc[i:i+1]),CovarianceClass5,MeanClass5,ProbailityOf5)>g6(np.asarray(df4.iloc[i:i+1]),CovarianceClass6,MeanClass6,(1 - ProbailityOf5)):\n",
    "            label=5\n",
    "            if(label==label_test[i]):\n",
    "                correct5+=1\n",
    "            else:\n",
    "                wrong5+=1\n",
    "        else:\n",
    "            label=6\n",
    "            if(label==label_test[i]):\n",
    "                correct6+=1\n",
    "            else:\n",
    "                wrong6+=1\n",
    "    return correct5,correct6,wrong5,wrong6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Mean Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MeanClass5=[0]*64 \n",
    "MeanClass6=[0]*64 \n",
    "total5=0                                                              #Total number of samples labeled as 5\n",
    "total6=0                                                              #Total number of samples labeled as 6\n",
    "for i in range(0,len(label_train)):\n",
    "    if (label_train[i]==5):\n",
    "        total5+=1\n",
    "        MeanClass5=np.add(MeanClass5,np.asarray(df2.iloc[i:i+1]))\n",
    "    else:\n",
    "        total6+=1\n",
    "        MeanClass6=np.add(MeanClass6,np.asarray(df2.iloc[i:i+1]))\n",
    "MeanClass5=MeanClass5/float(total5)                                   #estimate of Mean Vector for Class 5\n",
    "MeanClass6=MeanClass6/float(total6)                                   #estimate of Mean Vector for Class 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating probability of Class 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=float(total5)/len(label_train)                                      #Estimate of aprior probability of Class 5\n",
    "print \"Estimated aprior probability of class 5 :\",p\n",
    "print \"Estimated aprior probability of class 6 :\",1-p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Covariance Matrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_5 = [0]*64\n",
    "S_6 = [0]*64\n",
    "CovarianceClass5 = np.zeros((64,64))\n",
    "CovarianceClass6 = np.zeros((64,64))\n",
    "for i in range(0,len(label_train)):\n",
    "    if (label_train[i]==5):\n",
    "        S_5 = np.subtract(np.asarray(df2.iloc[i:i+1]),MeanClass5)\n",
    "        CovarianceClass5 = np.add(CovarianceClass5,np.matmul(S_5.transpose(),S_5))\n",
    "    else:\n",
    "        S_6 = np.subtract(np.asarray(df2.iloc[i:i+1]),MeanClass6)\n",
    "        CovarianceClass6 = np.add(CovarianceClass6,np.matmul(S_6.transpose(),S_6))\n",
    "CovarianceClass5 = CovarianceClass5/float(total5) #estimate of covariance matrix for class 5\n",
    "CovarianceClass6 = CovarianceClass6/float(total6) #estimate of covariance matrix for class 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CASE 1: Original Covariance matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Misclassification for CASE 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print \"CASE 1: Original Covariance matrices\"\n",
    "correct5,correct6,wrong5,wrong6=missclass(label_test,MeanClass5,CovarianceClass5,MeanClass6,CovarianceClass6,p)\n",
    "print \"------------------------------------\"\n",
    "print \"Number of data points with label 5 and classified as label 5 :\",correct5\n",
    "print \"Number of data points with label 5 and classified as label 6 :\",wrong6\n",
    "print \"Number of data points with label 6 and classified as label 6 :\",correct6\n",
    "print \"Number of data points with label 6 and classified as label 5 :\",wrong5\n",
    "print \"------------------------------------\"\n",
    "missclassification5=(float(wrong6)/(wrong6+correct5))*100\n",
    "missclassification6=(float(wrong5)/(wrong5+correct6))*100\n",
    "print('The misclassification rate for class 5 is %f '%(missclassification5) + '%')\n",
    "print('The misclassification rate for class 6 is %f '%(missclassification6) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix for CASE 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrix = np.matrix([[correct5,wrong6], [wrong5,correct6]])\n",
    "\n",
    "# Printing the Confusion Matrix\n",
    "\n",
    "print('The Confusion Matrix for CASE 1 is as follows :\\n')\n",
    "ConfusionMatrix= np.array(ConfusionMatrix)\n",
    "UpperTitle = [\"  Predicted Label 5\", \"  Predicted Label 6\"]\n",
    "LeftTitle = [\"Actual Label 5\", \"Actual Label 6\"]\n",
    "row_format =\"{:>15}\" * (len(UpperTitle) + 1)\n",
    "print row_format.format(\"\", *UpperTitle)\n",
    "for x, row in zip(LeftTitle, ConfusionMatrix):\n",
    "    print row_format.format(x, *row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CASE 2: Shared covariance matrix (Weighted Mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking the weighted average\n",
    "\n",
    "CovarianceClass5new = (p*CovarianceClass5)+((1-p)*CovarianceClass6) \n",
    "CovarianceClass6new = CovarianceClass5new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Misclassification for CASE 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"CASE 2: Shared covariance matrix (Weighted Mean)\"\n",
    "correct5,correct6,wrong5,wrong6=missclass(label_test,MeanClass5,CovarianceClass5new,MeanClass6,CovarianceClass6new,p)\n",
    "print \"------------------------------------\"\n",
    "print \"Number of data points with label 5 and classified as label 5 :\",correct5\n",
    "print \"Number of data points with label 5 and classified as label 6 :\",wrong6\n",
    "print \"Number of data points with label 6 and classified as label 6 :\",correct6\n",
    "print \"Number of data points with label 6 and classified as label 5 :\",wrong5\n",
    "print \"------------------------------------\"\n",
    "missclassification5=(float(wrong6)/(wrong6+correct5))*100\n",
    "missclassification6=(float(wrong5)/(wrong5+correct6))*100\n",
    "print('The misclassification rate for class 5 is %f '%(missclassification5) + '%')\n",
    "print('The misclassification rate for class 6 is %f '%(missclassification6) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix for CASE 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrix = np.matrix([[correct5,wrong6], [wrong5,correct6]])\n",
    "\n",
    "# Printing the Confusion Matrix\n",
    "\n",
    "print('The Confusion Matrix for CASE 2 is as follows :\\n')\n",
    "ConfusionMatrix= np.array(ConfusionMatrix)\n",
    "UpperTitle = [\"  Predicted Label 5\", \"  Predicted Label 6\"]\n",
    "LeftTitle = [\"Actual Label 5\", \"Actual Label 6\"]\n",
    "row_format =\"{:>15}\" * (len(UpperTitle) + 1)\n",
    "print row_format.format(\"\", *UpperTitle)\n",
    "for x, row in zip(LeftTitle, ConfusionMatrix):\n",
    "    print row_format.format(x, *row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CASE 3: Shared covariance matrix (Arithmetic Mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking the arithmetic mean\n",
    "CovarianceClass5new=(CovarianceClass5+CovarianceClass6)/float(2)\n",
    "CovarianceClass6new=CovarianceClass5new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Misclassification for CASE 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"CASE 3: Shared covariance matrix (Arithmetic Mean)\"\n",
    "correct5,correct6,wrong5,wrong6=missclass(label_test,MeanClass5,CovarianceClass5new,MeanClass6,CovarianceClass6new,p)\n",
    "print \"------------------------------------\"\n",
    "print \"Number of data points with label 5 and classified as label 5 :\",correct5\n",
    "print \"Number of data points with label 5 and classified as label 6 :\",wrong6\n",
    "print \"Number of data points with label 6 and classified as label 6 :\",correct6\n",
    "print \"Number of data points with label 6 and classified as label 5 :\",wrong5\n",
    "print \"------------------------------------\"\n",
    "missclassification5=(float(wrong6)/(wrong6+correct5))*100\n",
    "missclassification6=(float(wrong5)/(wrong5+correct6))*100\n",
    "print('The misclassification rate for class 5 is %f '%(missclassification5) + '%')\n",
    "print('The misclassification rate for class 6 is %f '%(missclassification6) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix for CASE 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrix = np.matrix([[correct5,wrong6], [wrong5,correct6]])\n",
    "\n",
    "# Printing the Confusion Matrix\n",
    "\n",
    "print('The Confusion Matrix for CASE 3 is as follows :\\n')\n",
    "ConfusionMatrix= np.array(ConfusionMatrix)\n",
    "UpperTitle = [\"  Predicted Label 5\", \"  Predicted Label 6\"]\n",
    "LeftTitle = [\"Actual Label 5\", \"Actual Label 6\"]\n",
    "row_format =\"{:>15}\" * (len(UpperTitle) + 1)\n",
    "print row_format.format(\"\", *UpperTitle)\n",
    "for x, row in zip(LeftTitle, ConfusionMatrix):\n",
    "    print row_format.format(x, *row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
